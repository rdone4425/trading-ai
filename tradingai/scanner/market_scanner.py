"""
å¸‚åœºæ‰«æå™¨ - ç»Ÿä¸€çš„å¸‚åœºæ•°æ®æ‰«æå’Œç­›é€‰å…¥å£
"""
from typing import List, Dict, Optional, Callable
import asyncio
import json
from datetime import datetime, timedelta
from pathlib import Path
from ..exchange import PlatformFactory
from ..exchange.platform.base import BasePlatform
from .symbol_parser import SymbolParser
from .. import config
from ..logger import get_logger
from ..utils import (
    align_to_timeframe,
    get_kline_range,
    is_kline_closed,
    time_until_next_kline,
    format_time,
    now_shanghai
)

logger = get_logger("scanner.market")


class MarketScanner:
    """å¸‚åœºæ‰«æå™¨"""
    
    def __init__(
        self,
        exchange_name: Optional[str] = None,
        timeframe: Optional[str] = None,
        lookback: Optional[int] = None,
        scan_limit: Optional[int] = None,
        hot_top_n: Optional[int] = None,
        volume_24h_top_n: Optional[int] = None,
        gainers_top_n: Optional[int] = None,
        losers_top_n: Optional[int] = None,
        default_quote: Optional[str] = None,
        min_volume: Optional[float] = None,
        min_change: Optional[float] = None,
        max_change: Optional[float] = None,
        kline_type: Optional[str] = None,
        analyzer = None,
        indicator_engine = None
    ):
        """
        åˆå§‹åŒ–æ‰«æå™¨
        
        Args:
            exchange_name: äº¤æ˜“æ‰€åç§°ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            timeframe: Kçº¿å‘¨æœŸï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            lookback: Kçº¿æ•°é‡ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            scan_limit: æ‰«æäº¤æ˜“å¯¹æ•°é‡ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            hot_top_n: çƒ­é—¨æ¦œé»˜è®¤æ•°é‡
            volume_24h_top_n: æˆäº¤é‡æ¦œé»˜è®¤æ•°é‡
            gainers_top_n: æ¶¨å¹…æ¦œé»˜è®¤æ•°é‡
            losers_top_n: è·Œå¹…æ¦œé»˜è®¤æ•°é‡
            default_quote: é»˜è®¤æŠ¥ä»·è´§å¸
            min_volume: æœ€å°æˆäº¤é‡è¿‡æ»¤
            min_change: æœ€å°æ¶¨è·Œå¹…è¿‡æ»¤ï¼ˆ%ï¼‰
            max_change: æœ€å¤§æ¶¨è·Œå¹…è¿‡æ»¤ï¼ˆ%ï¼‰
            kline_type: Kçº¿ç±»å‹ closed(å·²å®Œæˆ) æˆ– open(è¿›è¡Œä¸­)
        """
        # åŸºç¡€é…ç½®
        self.exchange_name = exchange_name or config.EXCHANGE_NAME
        self.timeframe = timeframe or config.TIMEFRAME
        self.lookback = lookback or config.LOOKBACK
        self.scan_limit = scan_limit or config.SCAN_TOP_N
        
        # Kçº¿ç±»å‹é…ç½®
        self.kline_type = (kline_type or config.KLINE_TYPE).lower()
        if self.kline_type not in ['closed', 'open']:
            self.kline_type = 'closed'
        
        # æ’è¡Œæ¦œé…ç½®ï¼ˆç»Ÿä¸€ä½¿ç”¨SCAN_TOP_Nï¼‰
        self.hot_top_n = hot_top_n or config.SCAN_TOP_N
        self.volume_24h_top_n = volume_24h_top_n or config.SCAN_TOP_N
        self.gainers_top_n = gainers_top_n or config.SCAN_TOP_N
        self.losers_top_n = losers_top_n or config.SCAN_TOP_N
        
        # ç­›é€‰é…ç½®
        self.default_quote = default_quote or config.DEFAULT_QUOTE
        self.min_volume = min_volume if min_volume is not None else 0
        self.min_change = min_change if min_change is not None else -100
        self.max_change = max_change if max_change is not None else 100
        
        # è¿è¡Œæ—¶å˜é‡
        self.platform: Optional[BasePlatform] = None
        self.symbols: List[str] = []
        self.tickers: Dict[str, Dict] = {}  # äº¤æ˜“å¯¹çš„è¡Œæƒ…æ•°æ®
        
        # AI åˆ†æç›¸å…³
        self.analyzer = analyzer
        self.indicator_engine = indicator_engine
        self.analysis_results: List[Dict] = []  # å­˜å‚¨ AI åˆ†æç»“æœ
        
        if self.analyzer:
            logger.info("âœ… å·²é›†æˆ AI åˆ†æå™¨")
        if self.indicator_engine:
            logger.info("âœ… å·²é›†æˆæŠ€æœ¯æŒ‡æ ‡å¼•æ“")
        
        # è‡ªåŠ¨æ‰«æç›¸å…³
        self._auto_scan_task: Optional[asyncio.Task] = None
        self._scan_callback: Optional[Callable] = None
        self._is_scanning: bool = False
    
    async def connect(self):
        """è¿æ¥åˆ°äº¤æ˜“æ‰€"""
        logger.info(f"è¿æ¥åˆ° {self.exchange_name}...")
        
        # ä½¿ç”¨å·¥å‚åˆ›å»ºå¹³å°
        self.platform = PlatformFactory.create_from_config()
        
        await self.platform.connect()
        logger.info("âœ… è¿æ¥æˆåŠŸ")
    
    async def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.platform:
            await self.platform.disconnect()
            logger.info("âœ… å·²æ–­å¼€è¿æ¥")
    
    async def analyze_symbol(self, symbol: str) -> Optional[Dict]:
        """
        åˆ†æå•ä¸ªäº¤æ˜“å¯¹ï¼ˆæ‰«æå™¨è·å–æ•°æ® â†’ è®¡ç®—æŒ‡æ ‡ â†’ ä¼ é€’ç»™AIåˆ†æï¼‰
        
        æ•°æ®æµç¨‹ï¼š
        1. æ‰«æå™¨ä»äº¤æ˜“æ‰€è·å–Kçº¿æ•°æ®
        2. æ‰«æå™¨ä½¿ç”¨æŒ‡æ ‡å¼•æ“è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        3. æ‰«æå™¨å°†Kçº¿å’ŒæŒ‡æ ‡ä¼ é€’ç»™AIåˆ†æå™¨
        4. AIåŸºäºæ‰«æå™¨ä¼ é€’çš„æ•°æ®è¿›è¡Œåˆ†æ
        
        Args:
            symbol: äº¤æ˜“å¯¹
        
        Returns:
            AI åˆ†æç»“æœï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        try:
            # 1. æ‰«æå™¨è·å– K çº¿æ•°æ®ï¼ˆä»äº¤æ˜“æ‰€ï¼‰
            klines = await self.get_klines(symbol)
            if not klines:
                logger.warning(f"âš ï¸  {symbol} æ‰«æå™¨æœªè·å–åˆ°Kçº¿æ•°æ®")
                return None
            
            logger.debug(f"ğŸ“Š æ‰«æå™¨è·å– {symbol} Kçº¿: {len(klines)} æ ¹")
            
            # æ˜¾ç¤ºKçº¿æ•°æ®ç»“æ„ç¤ºä¾‹ï¼ˆç¬¬ä¸€æ¡å’Œæœ€åä¸€æ¡ï¼‰
            if klines:
                logger.debug(f"   Kçº¿æ•°æ®ç»“æ„ç¤ºä¾‹ï¼ˆç¬¬ä¸€æ¡ï¼‰:")
                first_kline = klines[0]
                logger.debug(f"     æ—¶é—´: {first_kline.get('time', 'N/A')}, "
                           f"å¼€: {first_kline.get('open', 'N/A')}, "
                           f"é«˜: {first_kline.get('high', 'N/A')}, "
                           f"ä½: {first_kline.get('low', 'N/A')}, "
                           f"æ”¶: {first_kline.get('close', 'N/A')}, "
                           f"é‡: {first_kline.get('volume', 'N/A')}")
                if len(klines) > 1:
                    last_kline = klines[-1]
                    logger.debug(f"   Kçº¿æ•°æ®ç»“æ„ç¤ºä¾‹ï¼ˆæœ€åä¸€æ¡ï¼‰:")
                    logger.debug(f"     æ—¶é—´: {last_kline.get('time', 'N/A')}, "
                               f"å¼€: {last_kline.get('open', 'N/A')}, "
                               f"é«˜: {last_kline.get('high', 'N/A')}, "
                               f"ä½: {last_kline.get('low', 'N/A')}, "
                               f"æ”¶: {last_kline.get('close', 'N/A')}, "
                               f"é‡: {last_kline.get('volume', 'N/A')}")
            
            # 2. æ‰«æå™¨è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆåŸºäºè·å–çš„Kçº¿ï¼‰
            if not self.indicator_engine:
                logger.warning(f"âš ï¸  æœªé…ç½®æŠ€æœ¯æŒ‡æ ‡å¼•æ“ï¼Œæ— æ³•ä¸º {symbol} è®¡ç®—æŒ‡æ ‡")
                return None
            
            indicators = self.indicator_engine.calculate_all(klines)
            if not indicators:
                logger.warning(f"âš ï¸  {symbol} æŒ‡æ ‡è®¡ç®—å¤±è´¥")
                return None
            
            logger.debug(f"ğŸ“ˆ æ‰«æå™¨è®¡ç®— {symbol} æŒ‡æ ‡: {len(indicators)} ä¸ª")
            
            # æ˜¾ç¤ºæŒ‡æ ‡æ•°æ®ç»“æ„è¯¦æƒ…
            logger.debug(f"   æŒ‡æ ‡æ•°æ®è¯¦æƒ…:")
            try:
                import numpy as np
                HAS_NUMPY = True
            except ImportError:
                HAS_NUMPY = False
            
            for ind_name, ind_value in indicators.items():
                if HAS_NUMPY and isinstance(ind_value, np.ndarray):
                    if len(ind_value) > 0:
                        nan_count = np.sum(np.isnan(ind_value))
                        valid_count = len(ind_value) - nan_count
                        if valid_count > 0:
                            # è·å–æœ€åä¸€ä¸ªéNaNå€¼
                            valid_mask = ~np.isnan(ind_value)
                            valid_indices = np.where(valid_mask)[0]
                            last_valid = float(ind_value[valid_indices[-1]])
                            logger.debug(f"     {ind_name}: numpyæ•°ç»„[{len(ind_value)}], æœ‰æ•ˆå€¼: {valid_count}, NaN: {nan_count}, æœ€æ–°æœ‰æ•ˆå€¼: {last_valid}")
                        else:
                            logger.debug(f"     {ind_name}: numpyæ•°ç»„[{len(ind_value)}], å…¨éƒ¨ä¸ºNaN")
                    else:
                        logger.debug(f"     {ind_name}: ç©ºnumpyæ•°ç»„")
                elif isinstance(ind_value, (list, tuple)):
                    if len(ind_value) > 0:
                        last_val = ind_value[-1]
                        valid_count = sum(1 for v in ind_value if v is not None and str(v) != 'nan')
                        logger.debug(f"     {ind_name}: åˆ—è¡¨[{len(ind_value)}], æœ‰æ•ˆå€¼: {valid_count}, æœ€æ–°å€¼: {last_val}")
                    else:
                        logger.debug(f"     {ind_name}: ç©ºåˆ—è¡¨")
                elif isinstance(ind_value, dict):
                    logger.debug(f"     {ind_name}: å¤åˆæŒ‡æ ‡ {list(ind_value.keys())}")
                    for sub_name, sub_value in ind_value.items():
                        if HAS_NUMPY and isinstance(sub_value, np.ndarray):
                            if len(sub_value) > 0:
                                valid_mask = ~np.isnan(sub_value)
                                valid_count = np.sum(valid_mask)
                                if valid_count > 0:
                                    valid_indices = np.where(valid_mask)[0]
                                    last_valid = float(sub_value[valid_indices[-1]])
                                    logger.debug(f"       {sub_name}: numpyæ•°ç»„[{len(sub_value)}], æœ€æ–°æœ‰æ•ˆå€¼: {last_valid}")
                                else:
                                    logger.debug(f"       {sub_name}: numpyæ•°ç»„ï¼Œå…¨éƒ¨ä¸ºNaN")
                        elif isinstance(sub_value, (list, tuple)) and len(sub_value) > 0:
                            logger.debug(f"       {sub_name}: åˆ—è¡¨[{len(sub_value)}], æœ€æ–°å€¼: {sub_value[-1]}")
                        else:
                            logger.debug(f"       {sub_name}: {sub_value}")
                else:
                    logger.debug(f"     {ind_name}: {ind_value}")
            
            # 3. æ‰«æå™¨å°†æ•°æ®å’ŒæŒ‡æ ‡ä¼ é€’ç»™AIåˆ†æå™¨
            if not self.analyzer:
                logger.warning(f"âš ï¸  æœªé…ç½® AI åˆ†æå™¨ï¼Œæ— æ³•åˆ†æ {symbol}")
                return None
            
            logger.debug(f"ğŸ¤– ä¼ é€’æ•°æ®ç»™AIåˆ†æå™¨: {symbol}")
            logger.debug(f"   - Kçº¿æ•°æ®: {len(klines)} æ ¹ï¼ˆå­—å…¸æ ¼å¼ï¼ŒåŒ…å«time/open/high/low/close/volumeï¼‰")
            logger.debug(f"   - æŠ€æœ¯æŒ‡æ ‡: {list(indicators.keys())}ï¼ˆå­—å…¸æ ¼å¼ï¼Œå€¼ä¸ºæ•°ç»„æˆ–å¤åˆå­—å…¸ï¼‰")
            logger.debug(f"   - æ—¶é—´å‘¨æœŸ: {self.timeframe}")
            
            # AIåˆ†æå™¨åŸºäºæ‰«æå™¨ä¼ é€’çš„æ•°æ®å’ŒæŒ‡æ ‡è¿›è¡Œåˆ†æ
            analysis = await self.analyzer.analyze_market(
                symbol=symbol,
                klines=klines,      # æ‰«æå™¨è·å–çš„Kçº¿æ•°æ®
                indicators=indicators,  # æ‰«æå™¨è®¡ç®—çš„æŒ‡æ ‡æ•°æ®
                timeframe=self.timeframe
            )
            
            if analysis:
                logger.debug(f"âœ… AIåˆ†æå®Œæˆ: {symbol}")
            
            return analysis
        
        except Exception as e:
            logger.error(f"âŒ åˆ†æ {symbol} å¤±è´¥: {e}", exc_info=True)
            return None
    
    async def scan_and_analyze(self, concurrent: bool = True) -> List[Dict]:
        """
        æ‰«æå¸‚åœºå¹¶è‡ªåŠ¨è¿›è¡Œ AI åˆ†æ
        
        æ•°æ®æµç¨‹ï¼š
        1. æ‰«æå™¨æ‰«æå¸‚åœºï¼Œè·å–äº¤æ˜“å¯¹åˆ—è¡¨
        2. æ‰«æå™¨ä¸ºæ¯ä¸ªäº¤æ˜“å¯¹è·å–Kçº¿æ•°æ®ï¼ˆä»äº¤æ˜“æ‰€ï¼‰
        3. æ‰«æå™¨è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆåŸºäºKçº¿ï¼‰
        4. æ‰«æå™¨å°†Kçº¿å’ŒæŒ‡æ ‡ä¼ é€’ç»™AIåˆ†æå™¨
        5. AIåŸºäºæ‰«æå™¨ä¼ é€’çš„æ•°æ®å’ŒæŒ‡æ ‡è¿›è¡Œåˆ†æ
        
        Args:
            concurrent: æ˜¯å¦ä½¿ç”¨å¹¶å‘åˆ†æï¼ˆé»˜è®¤ Trueï¼Œå¯å¤§å¹…æå‡é€Ÿåº¦ï¼‰
        
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        try:
            # 1. æ‰«æäº¤æ˜“å¯¹
            symbols = await self.scan_symbols()
            logger.info(f"âœ… æ‰«æåˆ° {len(symbols)} ä¸ªäº¤æ˜“å¯¹")
            
            if not self.analyzer or not self.indicator_engine:
                logger.warning("âš ï¸  æœªé…ç½® AI åˆ†æå™¨æˆ–æŒ‡æ ‡å¼•æ“ï¼Œä»…è¿”å›äº¤æ˜“å¯¹åˆ—è¡¨")
                return []
            
            # 2. åˆ†æäº¤æ˜“å¯¹ï¼ˆå¹¶å‘æˆ–ä¸²è¡Œï¼‰
            self.analysis_results = []
            
            if concurrent and len(symbols) > 1:
                # å¹¶å‘åˆ†æï¼ˆæ¨èï¼‰
                logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘åˆ†æï¼ˆæœ€å¤§å¹¶å‘: {config.MAX_CONCURRENT_ANALYSIS}ï¼‰")
                await self._analyze_concurrent(symbols)
            else:
                # ä¸²è¡Œåˆ†æ
                logger.info("ğŸ“Š å¼€å§‹ä¸²è¡Œåˆ†æ")
                await self._analyze_sequential(symbols)
            
            logger.info(f"\nâœ… å®Œæˆåˆ†æ: {len(self.analysis_results)}/{len(symbols)}")
            
            # ä¿å­˜åˆ†æç»“æœï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if config.SAVE_ANALYSIS_RESULTS and self.analysis_results:
                self.save_analysis_results()
            
            return self.analysis_results
        
        except Exception as e:
            logger.error(f"âŒ æ‰«æåˆ†æå¤±è´¥: {e}")
            return []
    
    async def _analyze_sequential(self, symbols: List[str]):
        """ä¸²è¡Œåˆ†æäº¤æ˜“å¯¹ï¼ˆé€ä¸ªåˆ†æï¼‰"""
        for i, symbol in enumerate(symbols, 1):
            logger.info(f"è¿›åº¦: {i}/{len(symbols)} - {symbol}")
            result = await self.analyze_symbol(symbol)
            if result:
                self.analysis_results.append(result)
                logger.info(f"  âœ… {result['action']} (ç½®ä¿¡åº¦: {result['confidence']:.1%})")
    
    async def _analyze_concurrent(self, symbols: List[str]):
        """å¹¶å‘åˆ†æäº¤æ˜“å¯¹ï¼ˆåŒæ—¶åˆ†æå¤šä¸ªï¼Œé€Ÿåº¦æ›´å¿«ï¼‰"""
        import asyncio
        from tradingai import config
        
        # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°é‡
        semaphore = asyncio.Semaphore(config.MAX_CONCURRENT_ANALYSIS)
        
        async def analyze_with_semaphore(symbol: str, index: int):
            """å¸¦ä¿¡å·é‡æ§åˆ¶çš„åˆ†æå‡½æ•°"""
            async with semaphore:
                logger.info(f"ğŸ”„ å¼€å§‹åˆ†æ ({index}/{len(symbols)}): {symbol}")
                try:
                    result = await self.analyze_symbol(symbol)
                    if result:
                        logger.info(
                            f"âœ… å®Œæˆåˆ†æ ({index}/{len(symbols)}): {symbol} - "
                            f"{result['action']} (ç½®ä¿¡åº¦: {result['confidence']:.1%})"
                        )
                        return result
                    else:
                        logger.warning(f"âš ï¸  åˆ†æå¤±è´¥ ({index}/{len(symbols)}): {symbol}")
                        return None
                except Exception as e:
                    logger.error(f"âŒ åˆ†æå‡ºé”™ ({index}/{len(symbols)}): {symbol} - {e}")
                    return None
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [
            analyze_with_semaphore(symbol, i)
            for i, symbol in enumerate(symbols, 1)
        ]
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†æˆåŠŸçš„ç»“æœ
        for result in results:
            if result and not isinstance(result, Exception):
                self.analysis_results.append(result)
            elif isinstance(result, Exception):
                logger.error(f"âŒ ä»»åŠ¡å¼‚å¸¸: {result}")
    
    def cleanup_old_analysis_results(self, retention_days: int = 2, cleanup_interval_days: int = 1) -> int:
        """
        æ¯Nå¤©æ¸…ç†ä¸€æ¬¡ï¼Œä¿ç•™æœ€è¿‘Må¤©çš„åˆ†æç»“æœï¼Œåˆ é™¤æ›´æ—©çš„ç›®å½•å’Œæ–‡ä»¶
        
        Args:
            retention_days: ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤2å¤©ï¼ˆä¿ç•™ä»Šå¤©ã€æ˜¨å¤©ï¼‰
            cleanup_interval_days: æ¸…ç†é—´éš”å¤©æ•°ï¼Œé»˜è®¤1å¤©ï¼ˆæ¯å¤©æ‰§è¡Œä¸€æ¬¡æ¸…ç†ï¼‰
        
        Returns:
            æ¸…ç†çš„æ–‡ä»¶æ•°é‡
        """
        try:
            # è·å–é¡¹ç›®æ ¹ç›®å½•
            project_root = Path(__file__).parent.parent.parent
            base_dir = project_root / config.ANALYSIS_RESULTS_DIR
            
            if not base_dir.exists():
                return 0
            
            # è·å–å½“å‰æ—¥æœŸï¼ˆä¸Šæµ·æ—¶åŒºï¼‰
            now = now_shanghai()
            today = now.date()
            
            # æ£€æŸ¥ä¸Šæ¬¡æ¸…ç†æ—¶é—´ï¼ˆè®°å½•åœ¨éšè—æ–‡ä»¶ä¸­ï¼‰
            last_cleanup_file = base_dir / '.last_cleanup'
            should_cleanup = False
            
            if last_cleanup_file.exists():
                try:
                    last_cleanup_str = last_cleanup_file.read_text(encoding='utf-8').strip()
                    last_cleanup_date = datetime.strptime(last_cleanup_str, '%Y-%m-%d').date()
                    days_since_cleanup = (today - last_cleanup_date).days
                    # å¦‚æœè·ç¦»ä¸Šæ¬¡æ¸…ç†å·²ç»è¿‡äº†è‡³å°‘Nå¤©ï¼Œåˆ™æ‰§è¡Œæ¸…ç†
                    if days_since_cleanup >= cleanup_interval_days:
                        should_cleanup = True
                except Exception as e:
                    logger.warning(f"è¯»å–ä¸Šæ¬¡æ¸…ç†æ—¶é—´å¤±è´¥: {e}ï¼Œå°†æ‰§è¡Œæ¸…ç†")
                    should_cleanup = True
            else:
                # é¦–æ¬¡è¿è¡Œï¼Œæ‰§è¡Œæ¸…ç†
                should_cleanup = True
            
            if not should_cleanup:
                return 0  # æœªåˆ°æ¸…ç†æ—¶é—´
            
            # è®¡ç®—éœ€è¦åˆ é™¤çš„æ—¥æœŸï¼ˆè¶…è¿‡ä¿ç•™å¤©æ•°çš„æ—¥æœŸï¼‰
            # ä¿ç•™ï¼šä»Šå¤©ã€æ˜¨å¤©ã€å‰å¤©ï¼ˆå…±3å¤©ï¼‰ï¼Œåˆ é™¤ç¬¬4å¤©åŠæ›´æ—©çš„
            cutoff_date = today - timedelta(days=retention_days)
            
            deleted_count = 0
            deleted_dirs = []
            
            # éå†æ‰€æœ‰æ—¥æœŸç›®å½•
            for date_dir in base_dir.iterdir():
                if not date_dir.is_dir():
                    continue
                
                # æ£€æŸ¥æ—¥æœŸç›®å½•åæ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ—¥æœŸæ ¼å¼ï¼ˆYYYY-MM-DDï¼‰
                try:
                    dir_date = datetime.strptime(date_dir.name, '%Y-%m-%d').date()
                    
                    # å¦‚æœç›®å½•æ—¥æœŸæ—©äºæˆªæ­¢æ—¥æœŸï¼Œåˆ é™¤è¯¥ç›®å½•
                    if dir_date < cutoff_date:
                        dir_deleted = 0
                        
                        # åˆ é™¤ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
                        for file_path in date_dir.glob('analysis_*.json'):
                            try:
                                file_path.unlink()
                                deleted_count += 1
                                dir_deleted += 1
                            except Exception as e:
                                logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                                continue
                        
                        # åˆ é™¤ç›®å½•ä¸­çš„æ‰€æœ‰å‰©ä½™æ–‡ä»¶ï¼ˆå¦‚æœæœ‰éåˆ†ææ–‡ä»¶ï¼Œä¹Ÿä¸€èµ·åˆ é™¤ï¼‰
                        try:
                            remaining_items = list(date_dir.iterdir())
                            for item in remaining_items:
                                try:
                                    if item.is_file():
                                        item.unlink()
                                except Exception:
                                    pass
                        except Exception:
                            pass
                        
                        # åˆ é™¤ç›®å½•
                        try:
                            date_dir.rmdir()
                            deleted_dirs.append(date_dir.name)
                            logger.debug(f"ğŸ—‘ï¸  å·²åˆ é™¤åˆ†æç›®å½•: {date_dir.name}")
                        except Exception:
                            pass  # ç›®å½•ä¸ä¸ºç©ºï¼Œå¯èƒ½è¿˜æœ‰å­ç›®å½•
                    
                except ValueError:
                    # ä¸æ˜¯æœ‰æ•ˆçš„æ—¥æœŸç›®å½•ï¼ˆYYYY-MM-DDæ ¼å¼ï¼‰ï¼Œè·³è¿‡
                    continue
            
            # æ›´æ–°ä¸Šæ¬¡æ¸…ç†æ—¶é—´
            try:
                last_cleanup_file.write_text(today.strftime('%Y-%m-%d'), encoding='utf-8')
            except Exception as e:
                logger.warning(f"æ›´æ–°æ¸…ç†æ—¶é—´å¤±è´¥: {e}")
            
            if deleted_count > 0 or deleted_dirs:
                logger.info(
                    f"ğŸ—‘ï¸  æ¸…ç†å®Œæˆï¼šåˆ é™¤äº† {len(deleted_dirs)} ä¸ªç›®å½•ï¼Œå…± {deleted_count} ä¸ªåˆ†æç»“æœæ–‡ä»¶"
                    f"ï¼ˆä¿ç•™æœ€è¿‘ {retention_days} å¤©çš„æ•°æ®ï¼‰"
                )
                if deleted_dirs:
                    logger.debug(f"   å·²åˆ é™¤ç›®å½•: {', '.join(sorted(deleted_dirs))}")
            
            return deleted_count
        
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†åˆ†æç»“æœæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
            return 0
    
    def save_analysis_results(self, filename: Optional[str] = None) -> Optional[str]:
        """
        ä¿å­˜åˆ†æç»“æœåˆ° JSON æ–‡ä»¶ï¼ˆæŒ‰æ—¥æœŸåˆ†ç±»ï¼‰
        
        Args:
            filename: è‡ªå®šä¹‰æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³
        
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            if not self.analysis_results:
                logger.warning("æ²¡æœ‰åˆ†æç»“æœå¯ä¿å­˜")
                return None
            
            # åœ¨ä¿å­˜å‰æ¸…ç†æ—§æ–‡ä»¶ï¼ˆæ¯å¤©æ¸…ç†ä¸€æ¬¡ï¼Œåªä¿ç•™æœ€è¿‘2å¤©çš„æ•°æ®ï¼‰
            self.cleanup_old_analysis_results(retention_days=2, cleanup_interval_days=1)
            
            # è·å–å½“å‰æ—¶é—´ï¼ˆä¸Šæµ·æ—¶åŒºï¼‰
            now = now_shanghai()
            
            # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆç›¸å¯¹äºå½“å‰æ–‡ä»¶å‘ä¸Š3çº§ï¼‰
            project_root = Path(__file__).parent.parent.parent
            
            # åˆ›å»ºæŒ‰æ—¥æœŸåˆ†ç±»çš„ç›®å½•ç»“æ„ï¼štrading-ai/data/2025-11-01/
            date_dir = project_root / config.ANALYSIS_RESULTS_DIR / now.strftime('%Y-%m-%d')
            date_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆåªç”¨æ—¶é—´ï¼Œä¸å«æ—¥æœŸï¼‰
            if not filename:
                filename = f"analysis_{now.strftime('%H%M%S')}.json"
            
            filepath = date_dir / filename
            
            # æ„å»ºä¿å­˜æ•°æ®
            save_data = {
                "scan_time": now_shanghai().isoformat(),
                "exchange": self.exchange_name,
                "timeframe": self.timeframe,
                "kline_type": self.kline_type,
                "total_symbols": len(self.symbols),
                "analyzed_count": len(self.analysis_results),
                "summary": self.get_analysis_summary(),
                "results": self.analysis_results
            }
            
            # ä¿å­˜ä¸º JSON
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜: {filepath}")
            return str(filepath)
        
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}", exc_info=True)
            return None
    
    def get_analysis_summary(self) -> Dict:
        """
        è·å–åˆ†æç»“æœæ±‡æ€»
        
        Returns:
            æ±‡æ€»ç»Ÿè®¡
        """
        if not self.analysis_results:
            return {}
        
        # ç»Ÿè®¡å„ç§å»ºè®®
        actions = {}
        for result in self.analysis_results:
            action = result.get('action', 'æœªçŸ¥')
            actions[action] = actions.get(action, 0) + 1
        
        # è·å–é«˜ç½®ä¿¡åº¦çš„å»ºè®®
        threshold = config.AI_CONFIDENCE_THRESHOLD
        high_confidence = [
            r for r in self.analysis_results 
            if r.get('confidence', 0) >= threshold
        ]
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        sorted_results = sorted(
            self.analysis_results, 
            key=lambda x: x.get('confidence', 0), 
            reverse=True
        )
        
        # top_results åªä¿å­˜å…³é”®å­—æ®µï¼ˆé¿å…ä¸ results é‡å¤ï¼‰
        top_results_simplified = []
        for r in sorted_results[:5]:
            top_results_simplified.append({
                'symbol': r.get('symbol'),
                'action': r.get('action'),
                'confidence': r.get('confidence'),
                'trend': r.get('trend'),
                'entry_price': r.get('entry_price'),
                'stop_loss': r.get('stop_loss'),
                'take_profit': r.get('take_profit')
            })
        
        return {
            'total': len(self.analysis_results),
            'actions': actions,
            'high_confidence_count': len(high_confidence),
            'high_confidence_results': high_confidence,
            'top_results': top_results_simplified,  # åªä¿å­˜å…³é”®å­—æ®µï¼Œå®Œæ•´æ•°æ®åœ¨ results ä¸­
            'threshold': threshold
        }
    
    async def scan_symbols(self) -> List[str]:
        """
        æ‰«æäº¤æ˜“å¯¹
        
        Returns:
            äº¤æ˜“å¯¹åˆ—è¡¨
        """
        if not self.platform:
            raise RuntimeError("æœªè¿æ¥åˆ°äº¤æ˜“æ‰€ï¼Œè¯·å…ˆè°ƒç”¨ connect()")
        
        # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰äº¤æ˜“å¯¹
        if config.CUSTOM_SYMBOLS_RAW:
            # è§£æå¹¶æ ‡å‡†åŒ–äº¤æ˜“å¯¹
            custom_list = SymbolParser.parse_custom_symbols(
                config.CUSTOM_SYMBOLS_RAW,
                self.exchange_name
            )
            
            # å¦‚æœè§£æå¤±è´¥ï¼ˆå¯èƒ½æ˜¯å•ä¸ªè´§å¸ï¼‰ï¼Œå°è¯•æ™ºèƒ½æœç´¢
            if custom_list:
                # éªŒè¯äº¤æ˜“å¯¹æ˜¯å¦æœ‰æ•ˆ
                valid_symbols = []
                all_exchange_symbols = await self.platform.get_symbols()
                
                for symbol in custom_list:
                    # å¦‚æœå·²ç»æ˜¯å®Œæ•´äº¤æ˜“å¯¹ï¼Œç›´æ¥ä½¿ç”¨
                    if symbol in all_exchange_symbols:
                        valid_symbols.append(symbol)
                    else:
                        # å°è¯•æ™ºèƒ½æœç´¢ï¼ˆå¯èƒ½æ˜¯å•ä¸ªè´§å¸ï¼‰
                        searched = SymbolParser.smart_search(symbol, all_exchange_symbols, self.default_quote)
                        if searched:
                            valid_symbols.extend(searched)
                
                if valid_symbols:
                    # å»é‡
                    self.symbols = list(dict.fromkeys(valid_symbols))
                    
                    # è·å–ä»·æ ¼ä¿¡æ¯
                    all_tickers = await self.platform.get_all_tickers_24h()
                    self.tickers = {t["symbol"]: t for t in all_tickers if t["symbol"] in self.symbols}
                    
                    logger.info(f"âœ… ä½¿ç”¨è‡ªå®šä¹‰äº¤æ˜“å¯¹: {len(self.symbols)} ä¸ª")
                    logger.info(f"   äº¤æ˜“å¯¹: {', '.join(self.symbols[:10])}")
                    return self.symbols
        
        # å¦åˆ™ä½¿ç”¨æ‰«æç±»å‹
        logger.info("æ­£åœ¨æ ¹æ®æ‰«æç±»å‹è·å–äº¤æ˜“å¯¹...")
        scan_types = [t.strip().lower() for t in config.SCAN_TYPES.split(",") if t.strip()]
        
        all_tickers = []
        for scan_type in scan_types:
            if scan_type == "hot":
                tickers = await self.get_hot_symbols(top_n=config.SCAN_TOP_N)
                all_tickers.extend(tickers)
            elif scan_type == "volume":
                tickers = await self.get_top_volume(top_n=config.SCAN_TOP_N)
                all_tickers.extend(tickers)
            elif scan_type == "gainers":
                tickers = await self.get_top_gainers(top_n=config.SCAN_TOP_N)
                all_tickers.extend(tickers)
            elif scan_type == "losers":
                tickers = await self.get_top_losers(top_n=config.SCAN_TOP_N)
                all_tickers.extend(tickers)
        
        # å»é‡ï¼ˆä¿æŒé¡ºåºï¼Œä½¿ç”¨symbolä½œä¸ºkeyï¼‰
        unique_tickers = {}
        for ticker in all_tickers:
            symbol = ticker["symbol"]
            if symbol not in unique_tickers:
                unique_tickers[symbol] = ticker
        
        # é™åˆ¶ä¸ºç»Ÿä¸€æ•°é‡
        limited_tickers = list(unique_tickers.values())[:config.SCAN_TOP_N]
        
        # ä¿å­˜äº¤æ˜“å¯¹åˆ—è¡¨å’Œè¡Œæƒ…æ•°æ®
        self.symbols = [t["symbol"] for t in limited_tickers]
        self.tickers = {t["symbol"]: t for t in limited_tickers}
        
        logger.info(f"âœ… æ‰¾åˆ° {len(self.symbols)} ä¸ªäº¤æ˜“å¯¹")
        return self.symbols
    
    async def get_klines(self, symbol: str, kline_type: Optional[str] = None) -> List[Dict]:
        """
        è·å–å•ä¸ªäº¤æ˜“å¯¹çš„Kçº¿
        
        Args:
            symbol: äº¤æ˜“å¯¹
            kline_type: Kçº¿ç±»å‹ closed(å·²å®Œæˆ) æˆ– open(è¿›è¡Œä¸­)ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®
        
        Returns:
            Kçº¿æ•°æ®åˆ—è¡¨
        """
        if not self.platform:
            raise RuntimeError("æœªè¿æ¥åˆ°äº¤æ˜“æ‰€")
        
        kline_type = kline_type or self.kline_type
        
        klines = await self.platform.get_klines(
            symbol=symbol,
            interval=self.timeframe,
            limit=self.lookback,
            include_current=kline_type == 'open'  # è¿›è¡Œä¸­çš„Kçº¿éœ€è¦åŒ…å«å½“å‰
        )
        
        logger.debug(f"{symbol}: è·å–åˆ° {len(klines)} æ ¹Kçº¿ ({kline_type})")
        return klines
    
    async def scan_all_klines(self) -> Dict[str, List[Dict]]:
        """
        æ‰«ææ‰€æœ‰äº¤æ˜“å¯¹çš„Kçº¿
        
        Returns:
            {symbol: [klines]} å­—å…¸
        """
        if not self.symbols:
            await self.scan_symbols()
        
        logger.info(f"å¼€å§‹æ‰«æ {len(self.symbols)} ä¸ªäº¤æ˜“å¯¹çš„Kçº¿...")
        
        all_klines = {}
        for i, symbol in enumerate(self.symbols, 1):
            try:
                klines = await self.get_klines(symbol)
                all_klines[symbol] = klines
                
                if i % 10 == 0:  # æ¯10ä¸ªæ‰“å°ä¸€æ¬¡è¿›åº¦
                    logger.info(f"è¿›åº¦: {i}/{len(self.symbols)}")
            
            except Exception as e:
                logger.error(f"è·å– {symbol} Kçº¿å¤±è´¥: {e}")
                continue
        
        logger.info(f"âœ… æ‰«æå®Œæˆï¼ŒæˆåŠŸè·å– {len(all_klines)} ä¸ªäº¤æ˜“å¯¹çš„æ•°æ®")
        return all_klines
    
    async def scan_with_filter(
        self,
        min_volume: Optional[float] = None,
        max_symbols: Optional[int] = None
    ) -> Dict[str, List[Dict]]:
        """
        å¸¦è¿‡æ»¤æ¡ä»¶çš„æ‰«æ
        
        Args:
            min_volume: æœ€å°æˆäº¤é‡
            max_symbols: æœ€å¤§äº¤æ˜“å¯¹æ•°é‡
        
        Returns:
            è¿‡æ»¤åçš„Kçº¿æ•°æ®
        """
        all_klines = await self.scan_all_klines()
        
        # è¿‡æ»¤ä½æˆäº¤é‡
        if min_volume:
            filtered = {}
            for symbol, klines in all_klines.items():
                if klines:
                    latest_volume = klines[-1].get('volume', 0)
                    if latest_volume >= min_volume:
                        filtered[symbol] = klines
            
            logger.info(f"è¿‡æ»¤åå‰©ä½™ {len(filtered)} ä¸ªäº¤æ˜“å¯¹")
            all_klines = filtered
        
        # é™åˆ¶æ•°é‡
        if max_symbols and len(all_klines) > max_symbols:
            all_klines = dict(list(all_klines.items())[:max_symbols])
            logger.info(f"é™åˆ¶æ•°é‡ä¸º {max_symbols} ä¸ª")
        
        return all_klines
    
    async def get_market_summary(self) -> Dict:
        """
        è·å–å¸‚åœºæ‘˜è¦
        
        Returns:
            å¸‚åœºç»Ÿè®¡ä¿¡æ¯
        """
        if not self.symbols:
            await self.scan_symbols()
        
        summary = {
            "exchange": self.exchange_name,
            "total_symbols": len(self.symbols),
            "timeframe": self.timeframe,
            "lookback": self.lookback,
            "symbols": self.symbols[:10],  # å‰10ä¸ªç¤ºä¾‹
            "tickers": [self.tickers.get(s, {}) for s in self.symbols[:10]]  # å¸¦ä»·æ ¼ä¿¡æ¯
        }
        
        return summary
    
    def get_ticker(self, symbol: str) -> Optional[Dict]:
        """
        è·å–å•ä¸ªäº¤æ˜“å¯¹çš„è¡Œæƒ…æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹
        
        Returns:
            è¡Œæƒ…æ•°æ®ï¼ˆä»·æ ¼ã€æ¶¨è·Œå¹…ã€æˆäº¤é‡ç­‰ï¼‰
        """
        return self.tickers.get(symbol)
    
    def get_all_tickers(self) -> Dict[str, Dict]:
        """
        è·å–æ‰€æœ‰äº¤æ˜“å¯¹çš„è¡Œæƒ…æ•°æ®
        
        Returns:
            æ‰€æœ‰äº¤æ˜“å¯¹çš„è¡Œæƒ…å­—å…¸
        """
        return self.tickers
    
    async def start_auto_scan(
        self,
        callback: Optional[Callable] = None,
        align_to_kline: bool = True,
        wait_for_close: bool = True
    ):
        """
        å¯åŠ¨è‡ªåŠ¨æ‰«æ
        
        Args:
            callback: æ¯æ¬¡æ‰«æå®Œæˆåçš„å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶å‚æ•° (symbols, tickers)
            align_to_kline: æ˜¯å¦å¯¹å‡†Kçº¿å‘¨æœŸå¼€å§‹æ‰«æ
            wait_for_close: æ˜¯å¦ç­‰å¾…Kçº¿å®Œæˆï¼ˆä»…åœ¨ kline_type='closed' æ—¶æœ‰æ•ˆï¼‰
        """
        if self._is_scanning:
            logger.warning("è‡ªåŠ¨æ‰«æå·²åœ¨è¿è¡Œä¸­")
            return
        
        if not self.platform:
            raise RuntimeError("è¯·å…ˆè°ƒç”¨ connect() è¿æ¥åˆ°äº¤æ˜“æ‰€")
        
        self._scan_callback = callback
        self._is_scanning = True
        
        logger.info("ğŸ”„ å¯åŠ¨è‡ªåŠ¨æ‰«æ")
        logger.info(f"   å‘¨æœŸ: {self.timeframe}")
        logger.info(f"   Kçº¿ç±»å‹: {self.kline_type} ({'å·²å®Œæˆ' if self.kline_type == 'closed' else 'è¿›è¡Œä¸­'})")
        logger.info(f"   å¯¹å‡†Kçº¿: {'æ˜¯' if align_to_kline else 'å¦'}")
        
        # åˆ›å»ºå¹¶å¯åŠ¨æ‰«æä»»åŠ¡
        self._auto_scan_task = asyncio.create_task(
            self._auto_scan_loop(align_to_kline, wait_for_close)
        )
    
    async def stop_auto_scan(self):
        """åœæ­¢è‡ªåŠ¨æ‰«æ"""
        if not self._is_scanning:
            logger.warning("è‡ªåŠ¨æ‰«ææœªè¿è¡Œ")
            return
        
        logger.info("â¹ï¸  åœæ­¢è‡ªåŠ¨æ‰«æ")
        self._is_scanning = False
        
        if self._auto_scan_task:
            self._auto_scan_task.cancel()
            try:
                await self._auto_scan_task
            except asyncio.CancelledError:
                pass
            self._auto_scan_task = None
    
    async def _auto_scan_loop(self, align_to_kline: bool, wait_for_close: bool):
        """
        è‡ªåŠ¨æ‰«æå¾ªç¯
        
        Args:
            align_to_kline: æ˜¯å¦å¯¹å‡†Kçº¿å‘¨æœŸ
            wait_for_close: æ˜¯å¦ç­‰å¾…Kçº¿å®Œæˆ
        """
        try:
            # å¾ªç¯æ‰«æ
            while self._is_scanning:
                try:
                    # è®°å½•æ‰«ææ—¶é—´
                    scan_time = now_shanghai()
                    logger.info("="*60)
                    logger.info(f"ğŸ“Š å¼€å§‹æ‰«æ - {format_time(scan_time)}")
                    
                    # æ‰§è¡Œæ‰«æ
                    symbols = await self.scan_symbols()
                    
                    # è°ƒç”¨å›è°ƒå‡½æ•°ï¼ˆä¼ å…¥ scanner å®ä¾‹ï¼‰
                    if self._scan_callback:
                        try:
                            # æ£€æŸ¥å›è°ƒå‡½æ•°æ˜¯å¦æ˜¯åç¨‹å‡½æ•°
                            if asyncio.iscoroutinefunction(self._scan_callback):
                                await self._scan_callback(self, symbols, self.tickers)
                            else:
                                # åŒæ­¥å›è°ƒå‡½æ•°ï¼Œç›´æ¥è°ƒç”¨
                                result = self._scan_callback(self, symbols, self.tickers)
                                # å¦‚æœè¿”å›çš„æ˜¯åç¨‹å¯¹è±¡ï¼Œéœ€è¦await
                                if asyncio.iscoroutine(result):
                                    await result
                        except Exception as e:
                            logger.error(f"å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
                    
                    logger.info(f"âœ… æ‰«æå®Œæˆ - æ‰¾åˆ° {len(symbols)} ä¸ªäº¤æ˜“å¯¹")
                    
                    # ç­‰å¾…ä¸‹ä¸€æ ¹Kçº¿ï¼ˆå¦‚æœå¯ç”¨äº†Kçº¿å¯¹å‡†ï¼‰
                    if align_to_kline:
                        await self._wait_for_next_kline(wait_for_close=wait_for_close and self.kline_type == 'closed')
                    else:
                        # ä¸å¯¹å‡†Kçº¿ï¼Œåªæ˜¯ç®€å•ç­‰å¾…ä¸€æ®µæ—¶é—´
                        logger.info("â° ç­‰å¾… 60 ç§’åè¿›è¡Œä¸‹æ¬¡æ‰«æ...")
                        await asyncio.sleep(60)
                
                except asyncio.CancelledError:
                    raise
                except Exception as e:
                    logger.error(f"æ‰«æå¤±è´¥: {e}", exc_info=True)
                    # å‘ç”Ÿé”™è¯¯æ—¶ç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
                    logger.info("ç­‰å¾… 30 ç§’åé‡è¯•...")
                    await asyncio.sleep(30)
        
        except asyncio.CancelledError:
            logger.info("è‡ªåŠ¨æ‰«æå·²å–æ¶ˆ")
        finally:
            self._is_scanning = False
    
    async def _wait_for_next_kline(self, wait_for_close: bool = True):
        """
        ç­‰å¾…ä¸‹ä¸€æ ¹Kçº¿
        
        Args:
            wait_for_close: æ˜¯å¦ç­‰å¾…Kçº¿å®Œæˆï¼ˆTrue=ç­‰å¾…å®Œæˆï¼ŒFalse=ç­‰å¾…å¼€å§‹ï¼‰
        """
        now = now_shanghai()
        
        # è®¡ç®—ç­‰å¾…æ—¶é—´ï¼ˆtimedeltaå¯¹è±¡ï¼‰
        time_delta = time_until_next_kline(self.timeframe, now)
        wait_seconds = time_delta.total_seconds()
        
        if wait_for_close:
            # ç­‰å¾…å½“å‰Kçº¿å®Œæˆ
            target_time = now + time_delta
            action = "å®Œæˆ"
        else:
            # å·²ç»å¯¹å‡†äº†ï¼Œç­‰å¾…ä¸‹ä¸€æ ¹Kçº¿å¼€å§‹
            target_time = now + time_delta
            action = "å¼€å§‹"
        
        if wait_seconds > 0:
            logger.info(f"â° ç­‰å¾… {wait_seconds:.0f} ç§’ï¼Œç›´åˆ°ä¸‹ä¸€æ ¹ {self.timeframe} Kçº¿{action}...")
            logger.info(f"   å½“å‰æ—¶é—´: {format_time(now)}")
            logger.info(f"   ç›®æ ‡æ—¶é—´: {format_time(target_time)}")
            
            # åˆ†æ®µç­‰å¾…ï¼Œæ¯10ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            remaining = wait_seconds
            while remaining > 0 and self._is_scanning:
                wait = min(10, remaining)
                await asyncio.sleep(wait)
                remaining -= wait
                if remaining > 0 and remaining % 30 == 0:  # æ¯30ç§’æé†’ä¸€æ¬¡
                    logger.info(f"   å‰©ä½™ç­‰å¾…æ—¶é—´: {remaining:.0f} ç§’")
        
        logger.info(f"ğŸ¯ Kçº¿å·²{action}")
    
    @property
    def is_scanning(self) -> bool:
        """æ˜¯å¦æ­£åœ¨è‡ªåŠ¨æ‰«æ"""
        return self._is_scanning
    
    async def get_hot_symbols(self, top_n: Optional[int] = None, quote: Optional[str] = None) -> List[Dict]:
        """
        è·å–çƒ­é—¨äº¤æ˜“å¯¹ï¼ˆç»¼åˆæˆäº¤é‡å’Œæ¶¨è·Œå¹…ï¼‰
        
        Args:
            top_n: è¿”å›å‰Nä¸ªï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ hot_top_nï¼‰
            quote: æŠ¥ä»·è´§å¸ç­›é€‰ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ default_quoteï¼‰
        
        Returns:
            çƒ­é—¨äº¤æ˜“å¯¹åˆ—è¡¨
        """
        top_n = top_n or self.hot_top_n
        quote = quote or self.default_quote
        if not self.platform:
            raise RuntimeError("æœªè¿æ¥åˆ°äº¤æ˜“æ‰€")
        
        # è·å–æ‰€æœ‰24å°æ—¶è¡Œæƒ…
        tickers = await self.platform.get_all_tickers_24h()
        
        # è¿‡æ»¤æŠ¥ä»·è´§å¸
        if quote:
            tickers = [t for t in tickers if SymbolParser.get_quote(t["symbol"]) == quote.upper()]
        
        # è®¡ç®—çƒ­åº¦åˆ†æ•°å¹¶æ’åº
        for ticker in tickers:
            volume = ticker.get('volume', 0)
            price_change = abs(ticker.get('price_change_percent', 0))
            volume_score = volume / 1e9 if volume > 0 else 0
            change_score = price_change / 100
            ticker['hot_score'] = volume_score * 0.7 + change_score * 0.3
        
        sorted_tickers = sorted(tickers, key=lambda x: x.get('hot_score', 0), reverse=True)
        return sorted_tickers[:top_n]
    
    async def get_top_gainers(self, top_n: Optional[int] = None, quote: Optional[str] = None) -> List[Dict]:
        """
        è·å–æ¶¨å¹…æ¦œ
        
        Args:
            top_n: è¿”å›å‰Nä¸ªï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ gainers_top_nï¼‰
            quote: æŠ¥ä»·è´§å¸ç­›é€‰ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ default_quoteï¼‰
        
        Returns:
            æ¶¨å¹…æ¦œåˆ—è¡¨
        """
        top_n = top_n or self.gainers_top_n
        quote = quote or self.default_quote
        if not self.platform:
            raise RuntimeError("æœªè¿æ¥åˆ°äº¤æ˜“æ‰€")
        
        tickers = await self.platform.get_all_tickers_24h()
        
        # è¿‡æ»¤æŠ¥ä»·è´§å¸
        if quote:
            tickers = [t for t in tickers if SymbolParser.get_quote(t["symbol"]) == quote.upper()]
        
        # æŒ‰æ¶¨å¹…æ’åº
        sorted_tickers = sorted(tickers, key=lambda x: x.get('price_change_percent', 0), reverse=True)
        return sorted_tickers[:top_n]
    
    async def get_top_losers(self, top_n: Optional[int] = None, quote: Optional[str] = None) -> List[Dict]:
        """
        è·å–è·Œå¹…æ¦œ
        
        Args:
            top_n: è¿”å›å‰Nä¸ªï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ losers_top_nï¼‰
            quote: æŠ¥ä»·è´§å¸ç­›é€‰ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ default_quoteï¼‰
        
        Returns:
            è·Œå¹…æ¦œåˆ—è¡¨
        """
        top_n = top_n or self.losers_top_n
        quote = quote or self.default_quote
        if not self.platform:
            raise RuntimeError("æœªè¿æ¥åˆ°äº¤æ˜“æ‰€")
        
        tickers = await self.platform.get_all_tickers_24h()
        
        # è¿‡æ»¤æŠ¥ä»·è´§å¸
        if quote:
            tickers = [t for t in tickers if SymbolParser.get_quote(t["symbol"]) == quote.upper()]
        
        # æŒ‰è·Œå¹…æ’åº
        sorted_tickers = sorted(tickers, key=lambda x: x.get('price_change_percent', 0), reverse=False)
        return sorted_tickers[:top_n]
    
    async def get_top_volume(self, top_n: Optional[int] = None, quote: Optional[str] = None) -> List[Dict]:
        """
        è·å–æˆäº¤é‡æ’è¡Œ
        
        Args:
            top_n: è¿”å›å‰Nä¸ªï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ volume_24h_top_nï¼‰
            quote: æŠ¥ä»·è´§å¸ç­›é€‰ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ default_quoteï¼‰
        
        Returns:
            æˆäº¤é‡æ’è¡Œåˆ—è¡¨
        """
        top_n = top_n or self.volume_24h_top_n
        quote = quote or self.default_quote
        if not self.platform:
            raise RuntimeError("æœªè¿æ¥åˆ°äº¤æ˜“æ‰€")
        
        tickers = await self.platform.get_all_tickers_24h()
        
        # è¿‡æ»¤æŠ¥ä»·è´§å¸
        if quote:
            tickers = [t for t in tickers if SymbolParser.get_quote(t["symbol"]) == quote.upper()]
        
        # æŒ‰æˆäº¤é‡æ’åº
        sorted_tickers = sorted(tickers, key=lambda x: x.get('volume', 0), reverse=True)
        return sorted_tickers[:top_n]
    
    async def custom_scan(
        self,
        quote: Optional[str] = None,
        min_volume: Optional[float] = None,
        min_price: float = 0,
        max_price: float = float('inf'),
        min_change: Optional[float] = None,
        max_change: Optional[float] = None,
        bases: List[str] = None
    ) -> List[Dict]:
        """
        è‡ªå®šä¹‰ç­›é€‰äº¤æ˜“å¯¹
        
        Args:
            quote: æŠ¥ä»·è´§å¸ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ default_quoteï¼‰
            min_volume: æœ€å°æˆäº¤é‡ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„ min_volumeï¼‰
            min_price: æœ€ä½ä»·æ ¼
            max_price: æœ€é«˜ä»·æ ¼
            min_change: æœ€å°æ¶¨è·Œå¹…ï¼ˆ%ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„ min_changeï¼‰
            max_change: æœ€å¤§æ¶¨è·Œå¹…ï¼ˆ%ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„ max_changeï¼‰
            bases: æŒ‡å®šåŸºç¡€è´§å¸åˆ—è¡¨
        
        Returns:
            ç¬¦åˆæ¡ä»¶çš„äº¤æ˜“å¯¹åˆ—è¡¨
        
        Example:
            >>> # æŸ¥æ‰¾æ¶¨å¹… > 5%ï¼Œæˆäº¤é‡ > 1000ä¸‡çš„USDTäº¤æ˜“å¯¹
            >>> results = await scanner.custom_scan(
            ...     min_volume=10000000,
            ...     min_change=5
            ... )
        """
        if not self.platform:
            raise RuntimeError("æœªè¿æ¥åˆ°äº¤æ˜“æ‰€")
        
        # ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼
        quote = quote or self.default_quote
        min_volume = min_volume if min_volume is not None else self.min_volume
        min_change = min_change if min_change is not None else self.min_change
        max_change = max_change if max_change is not None else self.max_change
        
        tickers = await self.platform.get_all_tickers_24h()
        
        results = []
        for ticker in tickers:
            symbol = ticker["symbol"]
            
            # è§£æäº¤æ˜“å¯¹
            parsed = SymbolParser.parse(symbol)
            if not parsed:
                continue
            
            # æŠ¥ä»·è´§å¸è¿‡æ»¤
            if quote and parsed["quote"] != quote.upper():
                continue
            
            # åŸºç¡€è´§å¸è¿‡æ»¤
            if bases:
                bases_upper = [b.upper() for b in bases]
                if parsed["base"] not in bases_upper:
                    continue
            
            # æˆäº¤é‡è¿‡æ»¤
            if ticker.get('volume', 0) < min_volume:
                continue
            
            # ä»·æ ¼è¿‡æ»¤
            price = ticker.get('price', 0)
            if price < min_price or price > max_price:
                continue
            
            # æ¶¨è·Œå¹…è¿‡æ»¤
            change = ticker.get('price_change_percent', 0)
            if change < min_change or change > max_change:
                continue
            
            results.append(ticker)
        
        logger.info(f"è‡ªå®šä¹‰ç­›é€‰: æ‰¾åˆ° {len(results)} ä¸ªç¬¦åˆæ¡ä»¶çš„äº¤æ˜“å¯¹")
        return results
    
    async def search_symbol(self, input_str: str) -> List[str]:
        """
        æ™ºèƒ½æœç´¢äº¤æ˜“å¯¹
        
        Args:
            input_str: è¾“å…¥ï¼ˆå¦‚ "btc" æˆ– "BTCUSDT"ï¼‰
        
        Returns:
            åŒ¹é…çš„äº¤æ˜“å¯¹åˆ—è¡¨
        
        Example:
            >>> # è¾“å…¥ btcï¼Œè‡ªåŠ¨æ‰¾åˆ° BTCUSDT
            >>> symbols = await scanner.search_symbol("btc")
            ["BTCUSDT", "BTCBUSD", ...]
        """
        if not self.platform:
            raise RuntimeError("æœªè¿æ¥åˆ°äº¤æ˜“æ‰€")
        
        return await SymbolParser.search_from_exchange(input_str, self.platform)


async def create_scanner_from_config() -> MarketScanner:
    """
    ä»é…ç½®åˆ›å»ºæ‰«æå™¨ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Returns:
        é…ç½®å¥½çš„æ‰«æå™¨å®ä¾‹
    """
    scanner = MarketScanner()
    await scanner.connect()
    return scanner

